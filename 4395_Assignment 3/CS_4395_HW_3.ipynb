{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "WordNet displays and groups semantic relations between words. It holds words from multiple lanugages. There are sysnets, which are unordered sets that group similar words together.  The structure of WordNet includes having a short definition for each sysnet and examples of using them in a sentence. For relations, an inheritence tree is made, and it features hypernym and hyponyms where the latter is more specific.  "
      ],
      "metadata": {
        "id": "Tn88iL8kxBsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.wsd import lesk\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('sentiwordnet')\n",
        "nltk.download('book')\n",
        "from nltk.book import *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMG2Cjkky3SB",
        "outputId": "de5fdc78-051c-4d29-fce7-be60dc5f2c62"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data] Downloading collection 'book'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection book\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Noun Example"
      ],
      "metadata": {
        "id": "izvXGniNiizZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2\n",
        "syn_noun = wordnet.synsets(\"light\", pos='n')[0].name()\n",
        "syn_noun"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "oNkrRJity7qZ",
        "outputId": "9ad21f87-9afa-4c17-c24f-dcc8451acb6c"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'light.n.01'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Select one synset from the list of synsets. Extract its definition, usage examples, and lemmas.\n",
        "From your selected synset, traverse up the WordNet hierarchy as far as you can, outputting the\n",
        "synsets as you go. Write a couple of sentences observing the way that WordNet is organized for\n",
        "nouns.\n",
        "'''\n",
        "wordnet.synset(syn_noun).definition()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "VFU7d6k4zwaA",
        "outputId": "22a88aa1-7ce4-4698-9196-af2e2cfffd41"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(physics) electromagnetic radiation that can produce a visual sensation'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(wordnet.synset(syn_noun).examples()[0])"
      ],
      "metadata": {
        "id": "18-q1_kX0bV2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7d49517-7c24-4f54-abd5-606c6009b4f2"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the light was filtered through a soft glass window\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(wordnet.synset(syn_noun).lemma_names())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXOHBmBLz_oj",
        "outputId": "b660082c-9ad5-4a94-fcd7-5eeeabd98f29"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['light', 'visible_light', 'visible_radiation']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noun = wordnet.synset(syn_noun)"
      ],
      "metadata": {
        "id": "cuY8HFaK1fx9"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noun.hypernyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmy11FkV1m00",
        "outputId": "6c1b4345-0f92-4c4b-8dc1-266cd291a59e"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('actinic_radiation.n.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noun.hyponyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWibZxXE1pTO",
        "outputId": "3445bbe1-c029-481d-a64d-3ebf8064c248"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('beam.n.04'),\n",
              " Synset('candlelight.n.01'),\n",
              " Synset('corona.n.04'),\n",
              " Synset('counterglow.n.01'),\n",
              " Synset('daylight.n.02'),\n",
              " Synset('firelight.n.01'),\n",
              " Synset('fluorescence.n.01'),\n",
              " Synset('friar's_lantern.n.01'),\n",
              " Synset('gaslight.n.01'),\n",
              " Synset('glow.n.05'),\n",
              " Synset('half-light.n.01'),\n",
              " Synset('incandescence.n.01'),\n",
              " Synset('lamplight.n.01'),\n",
              " Synset('luminescence.n.01'),\n",
              " Synset('meteor.n.02'),\n",
              " Synset('moonlight.n.01'),\n",
              " Synset('radiance.n.01'),\n",
              " Synset('scintillation.n.01'),\n",
              " Synset('starlight.n.01'),\n",
              " Synset('streamer.n.01'),\n",
              " Synset('sunlight.n.01'),\n",
              " Synset('torchlight.n.01'),\n",
              " Synset('twilight.n.02')]"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hypernyms, hyponyms, meronyms, holonyms, antonym. \n",
        "noun.member_meronyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sR5wxHyt1vuK",
        "outputId": "d9a5e7b3-5cbe-48c5-ea7e-4de7e2a9973c"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noun.member_holonyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFXCeXbT10dl",
        "outputId": "7aabb9a3-4b46-49d5-a2be-aba5bc4ec7fa"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  ant = wordnet.synsets(syn_noun.split('.')[0], pos=wordnet.ADJ)[0]\n",
        "  print(ant.lemmas()[0].antonyms())\n",
        "except IndexError:\n",
        "  print('no antonyms')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqjlBz-g132h",
        "outputId": "0f8a650f-88ed-4afe-8504-aa9b7165f76d"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Lemma('heavy.a.01.heavy')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Verb Example"
      ],
      "metadata": {
        "id": "6u6hOopqiopC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "syn_v = wordnet.synsets(\"stand\", pos='v')[0].name()\n",
        "syn_v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "BF0iGpcc27ND",
        "outputId": "d02c93d2-88b7-4bb2-907f-0c05e237a23a"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'stand.v.01'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordnet.synset(syn_v).definition()"
      ],
      "metadata": {
        "id": "O0cBu7xY3LPa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6c836200-43d8-4f13-bc76-a12e105a9544"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'be standing; be upright'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(wordnet.synset(syn_v).lemma_names())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXTvw00AQlg5",
        "outputId": "eb54db58-1801-4053-ec27-2021a1ef8a60"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['stand', 'stand_up']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(wordnet.synset(syn_v).examples()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B84I4zKkRJQ9",
        "outputId": "53a62900-574c-4f88-8edc-6f82f3ad78ff"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We had to stand for the entire performance!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "verb = wordnet.synset(syn_v)"
      ],
      "metadata": {
        "id": "U4bxTbt3RLz-"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "verb.hypernyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJdJKg0hRSLv",
        "outputId": "049c8533-a678-4cbf-cf12-93ddf85083b9"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('rest.v.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "verb.hyponyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOT9pnN-RWgw",
        "outputId": "9a5d0d96-38ae-4885-e261-44a50c9ab276"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('line_up.v.03'), Synset('ramp.v.05'), Synset('stand_back.v.02')]"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "verb.member_meronyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csEMQ2TARZ0O",
        "outputId": "89e5c0b7-78bd-43ac-83a6-0b0392a44f0e"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "verb.member_holonyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiMinZRrRcxj",
        "outputId": "e9a6cfa0-ff57-42c7-8664-e8f7343e24c1"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  ant = wordnet.synsets(syn_v.split('.')[0], pos='v')[0]\n",
        "  print(ant.lemmas()[0].antonyms())\n",
        "except IndexError:\n",
        "  print('no antonyms')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o82iLhB_Rfy4",
        "outputId": "ca3202fd-b6d6-4557-e0ec-410c6897cee6"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Lemma('sit.v.01.sit'), Lemma('lie.v.02.lie')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordnet.morphy('disestablished')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "42R5-7sPR4hP",
        "outputId": "ec745577-2e63-42fb-8d68-9fc55742bbe7"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'disestablish'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Similarities"
      ],
      "metadata": {
        "id": "5jwDSOhzktPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first = wordnet.synset('school.n.01')\n",
        "second = wordnet.synset('academy.n.02')\n",
        "\n",
        "first.wup_similarity(second)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXCC9PbJSBSO",
        "outputId": "af725fa1-f5d0-41a2-d814-e20f6b88f7d0"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent = ['There', 'was', 'a', 'fast', 'car', '.']\n",
        "lesk(sent, 'fast')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LPil8NFSUIf",
        "outputId": "f4fe44c3-e1b9-4322-8553-c769fa77f0b7"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Synset('fast.s.10')"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lesk(sent, 'fast', pos='a'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcBU2VUtYvfg",
        "outputId": "a2259fa8-8cb6-471e-e656-c131001de257"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('fast.a.03')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SentiWordNet calculates positivity, negativity, and objectivity scores for every synset. This can be used when analyzing various reviews for an item on an e-commerce site."
      ],
      "metadata": {
        "id": "I89cQG4PSUnU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SentiWordNet"
      ],
      "metadata": {
        "id": "m_e6FnjjkyOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for ss in swn.senti_synsets('surprise'):\n",
        "  print(\"\\nnegative: \", ss.neg_score())\n",
        "  print(\"positive: \", ss.pos_score())\n",
        "  print(\"objective: \", ss.obj_score())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfAALMXEZ57n",
        "outputId": "6d3ffbdb-4f2f-499c-971e-c330754da234"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "negative:  0.25\n",
            "positive:  0.375\n",
            "objective:  0.375\n",
            "\n",
            "negative:  0.25\n",
            "positive:  0.0\n",
            "objective:  0.75\n",
            "\n",
            "negative:  0.125\n",
            "positive:  0.0\n",
            "objective:  0.875\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.125\n",
            "objective:  0.875\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent = 'I was curious to witness the great jar'\n",
        "neg = 0\n",
        "pos = 0\n",
        "tokens = sent.split()\n",
        "for token in tokens:\n",
        "    syn_list = list(swn.senti_synsets(token))\n",
        "    if syn_list:\n",
        "        syn = syn_list[0]\n",
        "        neg += syn.neg_score()\n",
        "        pos += syn.pos_score()\n",
        "    for ss in swn.senti_synsets(token):\n",
        "      print('\\ntoken: ', token)\n",
        "      print(\"\\nnegative: \", ss.neg_score())\n",
        "      print(\"positive: \", ss.pos_score())\n",
        "      print(\"objective: \", ss.obj_score())\n",
        "      print('******************')\n",
        "    \n",
        "print(\"neg\\tpos counts\")\n",
        "print(neg, '\\t', pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwoUA5OWapLG",
        "outputId": "c10e9c1f-095f-4861-fad3-e99518368374"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "token:  I\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0\n",
            "******************\n",
            "\n",
            "token:  I\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0\n",
            "******************\n",
            "\n",
            "token:  I\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0\n",
            "******************\n",
            "\n",
            "token:  I\n",
            "\n",
            "negative:  0.25\n",
            "positive:  0.0\n",
            "objective:  0.75\n",
            "******************\n",
            "\n",
            "token:  was\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0\n",
            "******************\n",
            "\n",
            "token:  was\n",
            "\n",
            "negative:  0.125\n",
            "positive:  0.25\n",
            "objective:  0.625\n",
            "******************\n",
            "\n",
            "token:  was\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0\n",
            "******************\n",
            "\n",
            "token:  was\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0\n",
            "******************\n",
            "\n",
            "token:  was\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0\n",
            "******************\n",
            "\n",
            "token:  was\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0\n",
            "******************\n",
            "\n",
            "token:  was\n",
            "\n",
            "negative:  0.125\n",
            "positive:  0.125\n",
            "objective:  0.75\n",
            "******************\n",
            "\n",
            "token:  was\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0\n",
            "******************\n",
            "\n",
            "token:  was\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0\n",
            "******************\n",
            "\n",
            "token:  was\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0\n",
            "******************\n",
            "\n",
            "token:  was\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0\n",
            "******************\n",
            "\n",
            "token:  was\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0\n",
            "******************\n",
            "\n",
            "token:  was\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0\n",
            "******************\n",
            "\n",
            "token:  was\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0\n",
            "******************\n",
            "\n",
            "token:  curious\n",
            "\n",
            "negative:  0.375\n",
            "positive:  0.125\n",
            "objective:  0.5\n",
            "******************\n",
            "\n",
            "token:  curious\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0\n",
            "******************\n",
            "\n",
            "token:  curious\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0\n",
            "******************\n",
            "\n",
            "token:  witness\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0\n",
            "******************\n",
            "\n",
            "token:  witness\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.25\n",
            "objective:  0.75\n",
            "******************\n",
            "\n",
            "token:  witness\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0\n",
            "******************\n",
            "\n",
            "token:  witness\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0\n",
            "******************\n",
            "\n",
            "token:  witness\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0\n",
            "******************\n",
            "\n",
            "token:  witness\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0\n",
            "******************\n",
            "\n",
            "token:  witness\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.125\n",
            "objective:  0.875\n",
            "******************\n",
            "\n",
            "token:  great\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0\n",
            "******************\n",
            "\n",
            "token:  great\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0\n",
            "******************\n",
            "\n",
            "token:  great\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.75\n",
            "objective:  0.25\n",
            "******************\n",
            "\n",
            "token:  great\n",
            "\n",
            "negative:  0.125\n",
            "positive:  0.25\n",
            "objective:  0.625\n",
            "******************\n",
            "\n",
            "token:  great\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.875\n",
            "objective:  0.125\n",
            "******************\n",
            "\n",
            "token:  great\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0\n",
            "******************\n",
            "\n",
            "token:  great\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0\n",
            "******************\n",
            "\n",
            "token:  jar\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0\n",
            "******************\n",
            "\n",
            "token:  jar\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0\n",
            "******************\n",
            "\n",
            "token:  jar\n",
            "\n",
            "negative:  0.125\n",
            "positive:  0.0\n",
            "objective:  0.875\n",
            "******************\n",
            "\n",
            "token:  jar\n",
            "\n",
            "negative:  0.125\n",
            "positive:  0.0\n",
            "objective:  0.875\n",
            "******************\n",
            "\n",
            "token:  jar\n",
            "\n",
            "negative:  0.125\n",
            "positive:  0.0\n",
            "objective:  0.875\n",
            "******************\n",
            "\n",
            "token:  jar\n",
            "\n",
            "negative:  0.5\n",
            "positive:  0.25\n",
            "objective:  0.25\n",
            "******************\n",
            "\n",
            "token:  jar\n",
            "\n",
            "negative:  0.375\n",
            "positive:  0.25\n",
            "objective:  0.375\n",
            "******************\n",
            "\n",
            "token:  jar\n",
            "\n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0\n",
            "******************\n",
            "neg\tpos counts\n",
            "0.375 \t 0.125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using SentiWordNet to calculate the polarity scores of each word from a sentence, I noticed most words were heavily objective. I find it interesting that some words like \"I\" and \"was\" are sometimes not 100% objective, with both of them scoring points for positivity or negativity. "
      ],
      "metadata": {
        "id": "aiXMeZYrciwD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collocations are when multiple words are strung together to create a different meaning. They can be a combination of nouns, adjectives, verbs, or adverbs."
      ],
      "metadata": {
        "id": "VICbB9chdM68"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collocation"
      ],
      "metadata": {
        "id": "Q-m-PrVAk3L_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text4.collocations()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93hzgr8zeG06",
        "outputId": "394dc1c6-ec99-40d8-8a30-a6454e1f8c9c"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "United States; fellow citizens; years ago; four years; Federal\n",
            "Government; General Government; American people; Vice President; God\n",
            "bless; Chief Justice; one another; fellow Americans; Old World;\n",
            "Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
            "tribes; public debt; foreign nations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = ' '.join(text4.tokens)"
      ],
      "metadata": {
        "id": "Z-N78VaIee4J"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "vocab = len(set(text4))\n",
        "oa = text.count('one another')/vocab\n",
        "print(\"p(one another) = \",oa )\n",
        "one = text.count('one')/vocab\n",
        "print(\"p(one) = \", one)\n",
        "another = text.count('another')/vocab\n",
        "print('p(another) = ', another)\n",
        "pmi = math.log2(oa / (one * another))\n",
        "print('pmi = ', pmi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZXlljmLehsF",
        "outputId": "422ad928-047a-4861-8f22-3d510047f77b"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p(one another) =  0.0021945137157107233\n",
            "p(one) =  0.0600498753117207\n",
            "p(another) =  0.006683291770573566\n",
            "pmi =  2.4510373676494677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the PMI score from above, since it's only a little higher than 0, 'one another' appear together in text4 a handful of times but not frequently. Both 'one' and 'another' are common words that could be used independent of each other, which explains the low score."
      ],
      "metadata": {
        "id": "CMwp8wbGgXfX"
      }
    }
  ]
}